This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.env.example
.gitignore
alembic.ini
api/app.py
api/blueprints/newsletter.py
api/blueprints/reservations.py
api/config.py
api/extensions.py
api/http.py
api/models.py
docker-compose.yml
Dockerfile
migrations/env.py
migrations/script.py.mako
migrations/versions/001_initial.py
README_BACKEND.md
requirements.txt
start.sh
tests/test_models.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".env.example">
# Flask
FLASK_ENV=development
FLASK_APP=api.app:create_app
SECRET_KEY=dev-secret-change-me

# Database
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=cafe_fausse
POSTGRES_HOST=db
POSTGRES_PORT=5432
DATABASE_URL=postgresql+psycopg2://postgres:postgres@db:5432/cafe_fausse

# API
PORT=8000
SLOT_MINUTES=30
</file>

<file path=".gitignore">
# Node modules
node_modules/

# Logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Runtime data
pids/
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov/

# Coverage directory used by tools like istanbul
coverage/

# nyc test coverage
.nyc_output/

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt/

# Bower dependency directory (https://bower.io/)
bower_components/

# dotenv environment variables file
.env
.env.*.local

# next.js build output
.next/

# Nuxt.js build / generate output
.nuxt/
dist/

# Parcel-bundler cache (https://parceljs.org/)
.cache/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm/

# Optional eslint cache
.eslintcache

# VS Code settings
.vscode/

# Mac system files
.DS_Store

# Windows system files
Thumbs.db
ehthumbs.db
Desktop.ini

# IDE files
.idea/
*.suo
*.ntvs*
*.njsproj
</file>

<file path="alembic.ini">
[alembic]
script_location = migrations
sqlalchemy.url = ${DATABASE_URL}

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console

[logger_sqlalchemy]
level = WARN
handlers = console
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers = console
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
</file>

<file path="api/app.py">
from flask import Flask, jsonify
from .extensions import db
from .config import Config
from .blueprints.reservations import bp as reservations_bp
from .blueprints.newsletter import bp as newsletter_bp

def create_app():
    app = Flask(__name__)
    app.config.from_object(Config)

    db.init_app(app)

    with app.app_context():
        # Lazy import models so metadata is registered
        from . import models  # noqa: F401
    app.register_blueprint(reservations_bp, url_prefix="/api/reservations")
    app.register_blueprint(newsletter_bp, url_prefix="/api/newsletter")

    @app.get("/health")
    def health():
        return jsonify(status="ok")

    return app
</file>

<file path="api/blueprints/newsletter.py">
from flask import Blueprint, request, jsonify
from ..extensions import db
from ..models import Customer

bp = Blueprint("newsletter", __name__)

@bp.post("")
def subscribe():
    payload = request.get_json(silent=True) or {}
    email = payload.get("email")
    if not email or "@" not in email:
        return jsonify(error="Invalid email"), 400

    name = payload.get("name") or "Subscriber"
    phone = payload.get("phone")

    cust = Customer.query.filter_by(email=email).one_or_none()
    if cust:
        cust.newsletter_opt_in = True
    else:
        cust = Customer(name=name, email=email, phone=phone, newsletter_opt_in=True)
        db.session.add(cust)

    db.session.commit()
    return jsonify(message="Email added to newsletter"), 200
</file>

<file path="api/blueprints/reservations.py">
from flask import Blueprint, request, jsonify, current_app
from sqlalchemy import select, func
from sqlalchemy.exc import IntegrityError
from datetime import datetime, timedelta, timezone
from ..extensions import db
from ..models import Reservation, Customer
from ..http import jerror

bp = Blueprint("reservations", __name__)
TOTAL_TABLES = 30

# --- Dev-only rate limiter (very simple) ---
_rate_state: dict[str, tuple[int, int]] = {}
_RATE_WINDOW = 60
_RATE_MAX = 12

def _allow(ip: str) -> bool:
    now = int(datetime.now(tz=timezone.utc).timestamp())
    window = now // _RATE_WINDOW
    count, win = _rate_state.get(ip, (0, window))
    if win != window:
        count, win = 0, window
    count += 1
    _rate_state[ip] = (count, win)
    return count <= _RATE_MAX

# --- Time parsing + slot rounding ---
def _parse_iso(s: str) -> datetime:
    s = s.strip()
    if s.endswith("Z"):
        s = s[:-1] + "+00:00"
    return datetime.fromisoformat(s)

def _round_to_slot(dt: datetime, minutes: int) -> datetime:
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    slot = minutes
    total = dt.hour * 60 + dt.minute
    floored = (total // slot) * slot
    return dt.replace(hour=floored // 60, minute=floored % 60, second=0, microsecond=0)

def _client_ip() -> str:
    fwd = request.headers.get("X-Forwarded-For")
    return (fwd.split(",")[0].strip() if fwd else request.remote_addr or "0.0.0.0")

# --- Endpoints ---

@bp.get("/availability")
def availability():
    t = request.args.get("time") or request.args.get("time_slot")
    if not t:
        return jerror(400, "MISSING_TIME", "Missing 'time' query parameter.")
    try:
        ts = _parse_iso(t)
    except Exception as e:
        return jerror(422, "BAD_TIME", "Invalid time format, expected ISO 8601.", str(e))
    slot_minutes = int(current_app.config.get("SLOT_MINUTES", 30))
    ts = _round_to_slot(ts, slot_minutes)

    booked = db.session.execute(
        select(func.count()).select_from(Reservation).where(Reservation.time_slot == ts)
    ).scalar_one()
    return jsonify(totalTables=TOTAL_TABLES, booked=int(booked), available=TOTAL_TABLES - int(booked), slot=ts.isoformat())

@bp.post("")
def create_reservation():
    ip = _client_ip()
    if not _allow(ip):
        return jerror(429, "RATE_LIMITED", "Too many requests. Try again shortly.")

    payload = request.get_json(silent=True) or {}
    required = ["time", "guests", "name", "email"]
    missing = [k for k in required if not payload.get(k)]
    if missing:
        return jerror(400, "MISSING_FIELDS", f"Missing fields: {', '.join(missing)}")

    try:
        ts = _parse_iso(payload["time"])
    except Exception as e:
        return jerror(422, "BAD_TIME", "Invalid time format, expected ISO 8601.", str(e))
    slot_minutes = int(current_app.config.get("SLOT_MINUTES", 30))
    ts = _round_to_slot(ts, slot_minutes)

    try:
        guests = int(payload["guests"])
        if guests < 1:
            return jerror(422, "BAD_GUESTS", "guests must be >= 1.")
    except Exception:
        return jerror(422, "BAD_GUESTS", "guests must be an integer >= 1.")

    name = str(payload["name"]).strip()
    email = str(payload["email"]).strip().lower()
    phone = str(payload.get("phone") or "").strip()

    customer = Customer.query.filter_by(email=email).one_or_none()
    if not customer:
        customer = Customer(name=name, email=email, phone=phone)
        db.session.add(customer)
        db.session.flush()

    booked = {t for (t,) in db.session.execute(
        select(Reservation.table_number).where(Reservation.time_slot == ts)
    ).all()}
    remaining = [t for t in range(1, TOTAL_TABLES + 1) if t not in booked]
    if not remaining:
        return jerror(409, "FULLY_BOOKED", "Time slot fully booked.")

    import random
    table = random.choice(remaining)
    res = Reservation(customer_id=customer.id, time_slot=ts, table_number=table)
    db.session.add(res)

    try:
        db.session.commit()
    except IntegrityError:
        db.session.rollback()
        return jerror(409, "RACE_LOST", "Just booked out. Pick another time.")

    return jsonify(reservationId=res.id, tableNumber=table, slot=ts.isoformat()), 201

@bp.get("")
def list_reservations():
    """
    Admin list for a single day with pagination.
    Query: ?date=YYYY-MM-DD&page=1&page_size=20
    """
    date_str = request.args.get("date")
    if not date_str:
        return jerror(400, "MISSING_DATE", "Missing 'date' query parameter (YYYY-MM-DD).")
    try:
        day = datetime.fromisoformat(date_str).date()
    except Exception as e:
        return jerror(422, "BAD_DATE", "Invalid date format. Use YYYY-MM-DD.", str(e))

    page = max(int(request.args.get("page", 1)), 1)
    page_size = min(max(int(request.args.get("page_size", 20)), 1), 100)

    start = datetime(day.year, day.month, day.day, tzinfo=timezone.utc)
    end = start + timedelta(days=1)

    q = (
        db.session.query(Reservation, Customer)
        .join(Customer, Reservation.customer_id == Customer.id)
        .filter(Reservation.time_slot >= start, Reservation.time_slot < end)
        .order_by(Reservation.time_slot.asc(), Reservation.table_number.asc())
    )

    total = q.count()
    rows = q.limit(page_size).offset((page - 1) * page_size).all()

    data = []
    for reservation, customer in rows:
        data.append({
            "id": reservation.id,
            "time": reservation.time_slot.isoformat(),
            "tableNumber": reservation.table_number,
            "customer": {
                "id": customer.id,
                "name": customer.name,
                "email": customer.email,
                "phone": customer.phone,
            },
        })


    return jsonify(page=page, pageSize=page_size, total=total, reservations=data)
</file>

<file path="api/config.py">
import os

class Config:
    SECRET_KEY = os.getenv("SECRET_KEY", "dev-secret")
    SQLALCHEMY_DATABASE_URI = os.getenv("DATABASE_URL", "sqlite:///local.db")
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    SLOT_MINUTES = int(os.getenv("SLOT_MINUTES", "30"))
</file>

<file path="api/extensions.py">
from flask_sqlalchemy import SQLAlchemy
db = SQLAlchemy()
</file>

<file path="api/http.py">
from flask import jsonify

def jerror(status: int, code: str, message: str, details: str | None = None):
    payload = {"code": code, "message": message}
    if details:
        payload["details"] = details
    return jsonify(payload), status
</file>

<file path="api/models.py">
from sqlalchemy import UniqueConstraint, func
from .extensions import db

class Customer(db.Model):
    __tablename__ = "customers"
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(120), nullable=False)
    email = db.Column(db.String(255), nullable=False, unique=True, index=True)
    phone = db.Column(db.String(32))
    newsletter_opt_in = db.Column(db.Boolean, nullable=False, default=False)
    created_at = db.Column(db.DateTime(timezone=True), nullable=False, server_default=func.now())
    reservations = db.relationship("Reservation", back_populates="customer", cascade="all, delete-orphan")

class Reservation(db.Model):
    __tablename__ = "reservations"
    id = db.Column(db.Integer, primary_key=True)
    customer_id = db.Column(db.Integer, db.ForeignKey("customers.id", ondelete="CASCADE"), nullable=False, index=True)
    time_slot = db.Column(db.DateTime(timezone=True), nullable=False, index=True)
    table_number = db.Column(db.Integer, nullable=False)
    created_at = db.Column(db.DateTime(timezone=True), nullable=False, server_default=func.now())
    customer = db.relationship("Customer", back_populates="reservations")

    __table_args__ = (UniqueConstraint("time_slot", "table_number", name="uq_reservation_slot_table"),)
</file>

<file path="docker-compose.yml">
services:
  db:
    image: postgres:15
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-cafe_fausse}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-cafe_fausse}"]
      interval: 5s
      timeout: 5s
      retries: 10

  api:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
    ports:
      - "${PORT:-8000}:8000"
    volumes:
      - ./:/app

volumes:
  pgdata:
</file>

<file path="Dockerfile">
FROM python:3.11-slim

# System deps for psycopg2
RUN apt-get update && apt-get install -y build-essential libpq-dev && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["sh", "-c", "flask --app api.app:create_app run --host=0.0.0.0 --port=8000"]
</file>

<file path="migrations/env.py">
from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
import os, sys

config = context.config
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from api.extensions import db  # noqa
import api.models  # noqa

target_metadata = db.metadata

def run_migrations_offline():
    url = os.getenv("DATABASE_URL")
    if not url:
        raise RuntimeError("DATABASE_URL is not set")
    context.configure(url=url, target_metadata=target_metadata, literal_binds=True, compare_type=True)
    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online():
    url = os.getenv("DATABASE_URL")
    if not url:
        raise RuntimeError("DATABASE_URL is not set")
    connectable = engine_from_config({"sqlalchemy.url": url}, prefix="sqlalchemy.", poolclass=pool.NullPool)
    with connectable.connect() as connection:
        context.configure(connection=connection, target_metadata=target_metadata, compare_type=True)
        with context.begin_transaction():
            context.run_migrations()
</file>

<file path="migrations/script.py.mako">

</file>

<file path="migrations/versions/001_initial.py">
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic.
revision = '001_initial'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    op.create_table(
        'customers',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('name', sa.String(length=120), nullable=False),
        sa.Column('email', sa.String(length=255), nullable=False),
        sa.Column('phone', sa.String(length=32), nullable=True),
        sa.Column('newsletter_opt_in', sa.Boolean(), nullable=False, server_default=sa.false()),
        sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, server_default=sa.func.now()),
    )
    op.create_index('ix_customers_email', 'customers', ['email'], unique=True)

    op.create_table(
        'reservations',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('customer_id', sa.Integer(), sa.ForeignKey('customers.id', ondelete='CASCADE'), nullable=False),
        sa.Column('time_slot', sa.DateTime(timezone=True), nullable=False),
        sa.Column('table_number', sa.Integer(), nullable=False),
        sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, server_default=sa.func.now()),
    )
    op.create_index('ix_reservations_customer_id', 'reservations', ['customer_id'])
    op.create_index('ix_reservations_time_slot', 'reservations', ['time_slot'])
    op.create_unique_constraint('uq_reservation_slot_table', 'reservations', ['time_slot', 'table_number'])

def downgrade():
    op.drop_constraint('uq_reservation_slot_table', 'reservations', type_='unique')
    op.drop_index('ix_reservations_time_slot', table_name='reservations')
    op.drop_index('ix_reservations_customer_id', table_name='reservations')
    op.drop_table('reservations')
    op.drop_index('ix_customers_email', table_name='customers')
    op.drop_table('customers')
</file>

<file path="README_BACKEND.md">
# Café Fausse — Backend (Flask + PostgreSQL)

This repo is the Week 1 backend scaffold. It includes:
- Flask app with blueprints
- SQLAlchemy models for `customers` and `reservations`
- Alembic migrations with a unique constraint on `(time_slot, table_number)`
- Docker Compose for Postgres and the API
- `.env.example` for configuration

## Quick start

```bash
# 1) Copy env
cp .env.example .env

# 2) Start Postgres + API
docker compose up --build

# 3) Apply migrations
docker compose exec api alembic upgrade head

# 4) (Optional) Run a basic smoke test
curl http://localhost:8000/health
```

## Useful commands

```bash
# Create a new migration after changing models
docker compose exec api alembic revision -m "your change" --autogenerate

# Upgrade/downgrade
docker compose exec api alembic upgrade head
docker compose exec api alembic downgrade -1

# Open a psql shell
docker compose exec db psql -U postgres -d cafe_fausse
```
</file>

<file path="requirements.txt">
Flask==3.0.3
Flask-SQLAlchemy==3.1.1
psycopg2-binary==2.9.9
alembic==1.13.2
python-dotenv==1.0.1
pydantic==2.8.2
</file>

<file path="start.sh">
#!/usr/bin/env bash
set -euo pipefail

if [ ! -f ".env" ]; then
  cp .env.example .env
  echo "Created .env from .env.example"
fi

export PORT=${PORT:-8000}

docker compose up -d db

echo "Waiting for DB..."
for i in {1..60}; do
  if docker compose exec -T db pg_isready -U "${POSTGRES_USER:-postgres}" -d "${POSTGRES_DB:-cafe_fausse}" >/dev/null 2>&1; then
    break
  fi
  sleep 1
done

echo "Applying DB migrations (one-off container)..."
docker compose run --rm api alembic upgrade head

echo "Starting API..."
docker compose up -d api

echo "Waiting for API health on http://localhost:${PORT}/health ..."
for i in {1..60}; do
  if curl -fsS "http://localhost:${PORT}/health" >/dev/null; then
    echo "API is healthy."
    echo "Ready:"
    echo "  Health:       http://localhost:${PORT}/health"
    echo "  Availability: http://localhost:${PORT}/api/reservations/availability?time=2025-09-10T19:00:00Z"
    exit 0
  fi
  sleep 1
done

echo "API did not become healthy in time."
docker compose logs api
exit 1
</file>

<file path="tests/test_models.py">
def test_truth():
    assert True
</file>

</files>
